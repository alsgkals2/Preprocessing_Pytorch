{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1022656-104b-4753-b78c-2824cd7d52b9",
   "metadata": {},
   "source": [
    "# setting imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "914d925b-abfa-4cc5-bf2c-85af02f2a293",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "path = 'data_path'\n",
    "list_imgs = []\n",
    "for a,b,c in os.walk(path):\n",
    "    for _c in c:\n",
    "        if '.jpg' in _c and 'ir' in _c and 'alpha' in _c:\n",
    "            list_imgs.append(os.path.join(a,_c))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50f146c-c46a-41d8-84b5-d9349392c3ab",
   "metadata": {},
   "source": [
    "# start aug test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5bd8316e-2d89-4c57-a02b-26f56c282819",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_augs(input_size, graynorm=False, bright=False, jitter=False, centercrop=False, affine=False, mask=False, blur=False):\n",
    "    if graynorm:\n",
    "        norm = transforms.Normalize(mean=[0.5,0.5,0.5], std=[0.5,0.5,0.5])\n",
    "    else:\n",
    "        norm = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                    std=[0.229, 0.224, 0.225])\n",
    "    aug_list = [\n",
    "            transforms.Resize((input_size,input_size)),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.ToTensor(),\n",
    "            # norm\n",
    "            ]\n",
    "    aug_list_val = [\n",
    "            transforms.Resize((input_size,input_size)),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.ToTensor(),\n",
    "            ]\n",
    "    train_aug = transforms.Compose(aug_list)\n",
    "    val_aug = transforms.Compose(aug_list_val)\n",
    "\n",
    "    return train_aug, val_aug\n",
    "\n",
    "from torchvision import transforms\n",
    "train_aug, val_aug = get_augs(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a672c7b3-64f9-45c0-a1cc-5f9ed8b713b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from torchvision.transforms import CenterCrop\n",
    "def get_augs(input_size, graynorm=False, bright=False, jitter=False, centercrop=False, affine=False, mask=False, blur=False):\n",
    "    if graynorm:\n",
    "        norm = transforms.Normalize(mean=[0.5,0.5,0.5], std=[0.5,0.5,0.5])\n",
    "    else:\n",
    "        norm = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                    std=[0.229, 0.224, 0.225])\n",
    "    aug_list = [\n",
    "            transforms.CenterCrop((input_size, input_size)),\n",
    "            transforms.ToTensor(),\n",
    "            ]\n",
    "    train_aug = transforms.Compose(aug_list)\n",
    "    return train_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1d9e424a-2711-4e5f-8686-626da828ac14",
   "metadata": {},
   "outputs": [],
   "source": [
    "augs_center = get_augs(128, centercrop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4aa0b69-3dd3-454a-b61d-7447a131eb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "for i in range(len(list_imgs)):\n",
    "    img = Image.open(list_imgs[i])\n",
    "    size_random = random.randint(128,168) \n",
    "    copy_img = transforms.Resize((size_random, size_random))(img)\n",
    "    plt.imshow(np.array(augs_center(copy_img)*255, dtype=np.int8).transpose((1,2,0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbe9757-20a6-400d-a31f-a059fcfbb22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from torchvision.transforms import CenterCrop\n",
    "from torchvision import transforms\n",
    "\n",
    "def get_augs(input_size, graynorm=False, bright=False, jitter=False, centercrop=False, affine=False, mask=False, blur=False):\n",
    "    if graynorm:\n",
    "        norm = transforms.Normalize(mean=[0.5,0.5,0.5], std=[0.5,0.5,0.5])\n",
    "    else:\n",
    "        norm = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                    std=[0.229, 0.224, 0.225])\n",
    "            transforms.GaussianBlur((3,3), sigma=(0.1, 1.0)), #check!!!\n",
    "            ]\n",
    "    train_aug = transforms.Compose(aug_list)\n",
    "    return train_aug\n",
    "augs_blur = get_augs(128, centercrop=True)\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "for i in range(len(list_imgs)):\n",
    "    img = Image.open(list_imgs[i])\n",
    "    img = img.convert('RGB')\n",
    "    plt.imshow(cv2.imread(list_imgs[0]))\n",
    "    plt.show()\n",
    "    copy_img = transforms.Resize((128, 128))(img)\n",
    "    plt.imshow(np.array(augs_blur(copy_img)))\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c65d9c9-1c95-4fc1-b8f8-42687b71d9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from torchvision.transforms import CenterCrop\n",
    "from torchvision import transforms\n",
    "\n",
    "def get_augs(input_size, graynorm=False, bright=False, jitter=False, centercrop=False, affine=False, mask=False, blur=False):\n",
    "    if graynorm:\n",
    "        norm = transforms.Normalize(mean=[0.5,0.5,0.5], std=[0.5,0.5,0.5])\n",
    "    else:\n",
    "        norm = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                    std=[0.229, 0.224, 0.225])\n",
    "    aug_list = [\n",
    "            transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), shear=0.15), #check!!!\n",
    "            ]\n",
    "    train_aug = transforms.Compose(aug_list)\n",
    "    return train_aug\n",
    "augs_affine = get_augs(128, centercrop=True)\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "for i in range(len(list_imgs)):\n",
    "    img = Image.open(list_imgs[i])\n",
    "    img = img.convert('RGB')\n",
    "    plt.imshow(cv2.imread(list_imgs[0]))\n",
    "    plt.show()\n",
    "    copy_img = transforms.Resize((128, 128))(img)\n",
    "    plt.imshow(np.array((copy_img)))\n",
    "    plt.show()\n",
    "    plt.imshow(np.array(augs_affine(copy_img)))\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1e7de9-3a53-4ae1-9b70-1383a7f6072f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from torchvision.transforms import CenterCrop\n",
    "from torchvision import transforms\n",
    "\n",
    "def get_augs(input_size, graynorm=False, bright=False, jitter=False, centercrop=False, affine=False, mask=False, blur=False):\n",
    "    if graynorm:\n",
    "        norm = transforms.Normalize(mean=[0.5,0.5,0.5], std=[0.5,0.5,0.5])\n",
    "    else:\n",
    "        norm = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                    std=[0.229, 0.224, 0.225])\n",
    "    aug_list = [\n",
    "            transforms.RandomAffine(degrees=0,shear=(-10,10,-10,10)), #check!!!\n",
    "            ]\n",
    "    \"\"\"\n",
    "    apply(img, torchvision.transforms.ColorJitter(brightness=0.5))   #밝기\n",
    "    apply(img, torchvision.transforms.ColorJitter(contrast=0.5))     #대비\n",
    "    apply(img, torchvision.transforms.ColorJitter(saturation=0.5))   #채도\n",
    "    apply(img, torchvision.transforms.ColorJitter(hue=0.5))          #색조\n",
    "    \"\"\"\n",
    "    train_aug = transforms.Compose(aug_list)\n",
    "    return train_aug\n",
    "augs_affine = get_augs(128, centercrop=True)\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "for i in range(len(list_imgs)):\n",
    "    img = Image.open(list_imgs[i])\n",
    "    img = img.convert('RGB')\n",
    "    plt.imshow(cv2.imread(list_imgs[0]))\n",
    "    plt.show()\n",
    "    copy_img = transforms.Resize((128, 128))(img)\n",
    "    plt.imshow(np.array((copy_img)))\n",
    "    plt.show()\n",
    "    plt.imshow(np.array(augs_affine(copy_img)))\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f789ed73-72bc-4c08-aebb-7209bc80f259",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from torchvision.transforms import RandomResizedCrop\n",
    "from torchvision import transforms\n",
    "def get_augs(input_size, graynorm=False, bright=False, jitter=False, centercrop=False, affine=False, mask=False, blur=False):\n",
    "    if graynorm:\n",
    "        norm = transforms.Normalize(mean=[0.5,0.5,0.5], std=[0.5,0.5,0.5])\n",
    "    else:\n",
    "        norm = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                    std=[0.229, 0.224, 0.225])\n",
    "    aug_list = [\n",
    "            transforms.Resize((input_size,input_size)),\n",
    "            transforms.RandomResizedCrop((input_size,input_size), scale=(0.4,0.6), ratio=(1.,1.)),\n",
    "            transforms.ToTensor(),\n",
    "            ]\n",
    "    train_aug = transforms.Compose(aug_list)\n",
    "    return train_aug\n",
    "\n",
    "augs_center = get_augs(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d08b73-a1fb-48c5-a232-25a834df54a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "# import Image\n",
    "for i in range(len(list_imgs)):\n",
    "    img = Image.open(list_imgs[i])\n",
    "    copy_img = transforms.Resize((128, 128))(img)\n",
    "    plt.imshow(np.array(copy_img, dtype=np.int8))#.transpose((1,2,0)))\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8deba38d-cac2-4bb0-b9bf-f16cf13b6920",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "# import Image\n",
    "for i in range(len(list_imgs)):\n",
    "    img = Image.open(list_imgs[i])\n",
    "    copy_img = transforms.Resize((128, 128))(img)\n",
    "    plt.imshow(np.array(augs_center(copy_img)*255, dtype=np.int8).transpose((1,2,0)))\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076e110c-a5b5-4e25-bc86-c1e9d84f0b24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193c1e47-ef39-4404-925c-e1f97d3d9c7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clipenv3",
   "language": "python",
   "name": "clipenv3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
