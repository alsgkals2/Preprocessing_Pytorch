{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d777b845-26cc-4ecd-bb2f-a54e17e60ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_grad_cam import GradCAM, HiResCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf8fa7cb-f047-47a7-b283-7942add25d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_real = []\n",
    "list_fake = []\n",
    "import os\n",
    "for a,b,c in os.walk('datapath'):\n",
    "    for _c in c:\n",
    "        if '.jpg' in _c or '.png' in _c:\n",
    "            if '/real' in a:\n",
    "                list_real.append(os.path.join(a,_c))\n",
    "            else:\n",
    "                list_fake.append(os.path.join(a,_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2152b187-556b-40e3-a84c-74e3f07a5958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import timm\n",
    "import torch\n",
    "model = timm.create_model(\"hf_hub:timm/mobilenetv4_conv_small.e2400_r224_in1k\", num_classes=1, pretrained=False).cuda()\n",
    "weight = 'model_best_val1_hter.pth.tar'\n",
    "model.load_state_dict(torch.load(weight)['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e93cf55-45c2-4fe5-90a5-9290d7715ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_list = list_real+list_fake\n",
    "import random\n",
    "random.shuffle(all_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ee6479-d1d3-4674-adf5-cb4b666d457e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "target_layers = [model.blocks, model.conv_stem, model.norm_head]\n",
    "for i, imgpath in enumerate(all_list):\n",
    "    # ten_img_rgb = torch.tensor(cv2.imread(img))\n",
    "    img = cv2.imread(imgpath)\n",
    "    img = cv2.resize(img, (92,92))\n",
    "    img = (img/255.).astype(np.float32)\n",
    "    img = img.transpose((2,0,1))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    img_rgb = copy.deepcopy(img)\n",
    "    img_rgb[0] = (img_rgb[0] - mean[0]) / std[0] \n",
    "    img_rgb[1] = (img_rgb[1] - mean[1]) / std[1] \n",
    "    img_rgb[2] = (img_rgb[2] - mean[2]) / std[2] \n",
    "    t = 0 if '/real/' in imgpath else 1 # if classes is only two\n",
    "    t = 0 # if classes is only one\n",
    "    targets = [ClassifierOutputTarget(t)]\n",
    "    with GradCAM(model=model, target_layers=target_layers) as cam:\n",
    "        # You can also pass aug_smooth=True and eigen_smooth=True, to apply smoothing.\n",
    "        grayscale_cam = cam(input_tensor=torch.tensor(img_rgb).unsqueeze(0), targets=targets)\n",
    "        # In this example grayscale_cam has only one image in the batch:\n",
    "        grayscale_cam = grayscale_cam[0, :]\n",
    "        visualization = show_cam_on_image(np.array(torch.tensor(img).permute((1,2,0)).cpu().detach()), grayscale_cam, use_rgb=True)\n",
    "        # You can also get the model outputs without having to redo inference\n",
    "        model_outputs = cam.outputs\n",
    "        print(imgpath)\n",
    "        plt.figure(figsize=(3, 2))\n",
    "        plt.imshow(visualization)\n",
    "        plt.show()\n",
    "        if i == 20:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21df8539-85a3-4cd0-821d-8f9d0df45717",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clipenv3",
   "language": "python",
   "name": "clipenv3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
