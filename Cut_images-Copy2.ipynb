{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb21ba60-3032-4183-bef6-24e23c1af631",
   "metadata": {},
   "source": [
    "### CUT AND SAVE IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a700385-d3d9-47f1-99f3-4d0f518ab8dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import torchvision \n",
    "from torchvision import transforms, datasets\n",
    "import torchvision.datasets as dataset\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import time\n",
    "import glob\n",
    "import torch.optim as optim\n",
    "from torch.cuda.amp import autocast\n",
    "from torch.cuda.amp import GradScaler\n",
    "print(torch.__version__)\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4ed343e-f7be-4f28-a5de-8db10384a4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "200\n",
      "tensor([[0.9725, 0.6133, 0.1102,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.2616, 0.2720, 0.1264,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.1939, 0.4648, 0.2133,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "t = torch.tensor(np.random.random_sample((3,200,100)))\n",
    "# functional.crop(t,100,200,200,200)\n",
    "based_t = torch.zeros((3,500,300))\n",
    "based_t[:,:200,:100] = t\n",
    "print(based_t.size(1))\n",
    "print(t.size(1))\n",
    "print(based_t[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcbeb204-09a2-4692-aeef-2af816248b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms\n",
    "from torchvision.transforms import functional\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "func_crop = functional.crop\n",
    "\n",
    "def cut_img_png(img_path_list, save_path, stride=128,img_size = 256):\n",
    "    toimage = transforms.ToPILImage()\n",
    "    totensor = transforms.ToTensor()\n",
    "    os.makedirs(f'{save_path}{img_size}', exist_ok=True)\n",
    "\n",
    "    for path in tqdm(img_path_list):\n",
    "        num=0\n",
    "        img = Image.open(path)\n",
    "        img = totensor(img)\n",
    "        for top in range(0, img.size()[2], stride):\n",
    "            for left in range(0, img.size()[1], stride):\n",
    "                based_tensor = torch.zeros((3,img_size,img_size))\n",
    "                arr_cropped = func_crop(img,top,left,img_size,img_size)\n",
    "                w, h = arr_cropped.size(1), arr_cropped.size(2)\n",
    "                based_tensor[:, :w, :h] = arr_cropped\n",
    "                to_pil = toimage(based_tensor)\n",
    "                title = path[path.rfind('/'):]\n",
    "                # title = path[:path.rfind('/')]\n",
    "                to_pil.save(f'{save_path}/{img_size}/{title}_{num}.png')\n",
    "                num+=1\n",
    "                \n",
    "def cut_img_npy(img_path_list, save_path, stride=128,img_size = 256):\n",
    "    os.makedirs(f'{save_path}/{img_size}', exist_ok=True)\n",
    "    for path in tqdm(img_path_list):\n",
    "        num = 0\n",
    "        img = cv2.imread(path)\n",
    "        for top in range(0, img.shape[0], stride):\n",
    "            for left in range(0, img.shape[1], stride):\n",
    "                piece = np.zeros([img_size, img_size, 3], np.uint8)\n",
    "                temp = img[top:top+img_size, left:left+img_size, :]\n",
    "                piece[:temp.shape[0], :temp.shape[1], :] = temp\n",
    "                title = path[path.rfind('/'):]\n",
    "                filename= f'{save_path}/{img_size}/{title}_{num}.npy'\n",
    "                # if not os.path.isfile(filename):\n",
    "                np.save(filename,piece)\n",
    "                num+=1\n",
    "\n",
    "def cut_img_half(img_path_list, save_path):\n",
    "    os.makedirs(f'{save_path}half', exist_ok=True)\n",
    "    num = 0\n",
    "    for path in tqdm(img_path_list):\n",
    "        img = cv2.imread(path)\n",
    "        len_half_x = img.shape[1]//2\n",
    "        ratio_len = img.shape[0]/img.shape[1]\n",
    "        len_half_y = img.shape[0]//2\n",
    "        for top in range(0, img.shape[0], len_half_y//2):\n",
    "            for left in range(0, img.shape[1], len_half_x//2):\n",
    "                piece = np.zeros([len_half_y, len_half_x, 3], np.uint8)\n",
    "                temp = img[top:top+len_half_y, left:left+len_half_x, :]\n",
    "                piece[:temp.shape[0], :temp.shape[1], :] = temp\n",
    "                np.save(f'{save_path}half/{num}.npy', piece)\n",
    "                num+=1\n",
    "\n",
    "def cut_img_6devide(img_path_list, save_path):\n",
    "    from tqdm import tqdm\n",
    "    os.makedirs(f'{save_path}6devide', exist_ok=True)\n",
    "    num = 0\n",
    "    for path in tqdm(img_path_list):\n",
    "        img = cv2.imread(path)\n",
    "        len_x = img.shape[1]//6\n",
    "        len_y = img.shape[0]//6\n",
    "        for top in range(0, img.shape[0], len_y//2):\n",
    "            for left in range(0, img.shape[1], len_x//2):\n",
    "                piece = np.zeros([len_y, len_x, 3], np.uint8)\n",
    "                temp = img[top:top+len_y, left:left+len_x, :]\n",
    "                piece[:temp.shape[0], :temp.shape[1], :] = temp\n",
    "                np.save(f'{save_path}6devide/{num}.npy', piece)\n",
    "                num+=1                \n",
    "                \n",
    "\n",
    "def cut_img_fullscreen(img_path_list, save_path):\n",
    "    from tqdm import tqdm\n",
    "    os.makedirs(f'{save_path}full', exist_ok=True)\n",
    "    num = 0\n",
    "    for path in tqdm(img_path_list):\n",
    "        img = cv2.imread(path)\n",
    "        len_x = img.shape[1]\n",
    "        len_y = img.shape[0]\n",
    "        np.save(f'{save_path}full/{num}_full.npy', img)\n",
    "        num+=1                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abeeedf7-931b-4c57-bfb7-f8743616ac22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2792/2792 [30:49<00:00,  1.51it/s]  \n",
      "100%|██████████| 2792/2792 [30:37<00:00,  1.52it/s]  \n"
     ]
    }
   ],
   "source": [
    "cut_img_npy(list_path, '/media/data1/mhkim/SR/DOTA2.0/train/images')\n",
    "cut_img_npy(list_path_2, '/media/data1/mhkim/SR/DOTA2.0/train/images_x2_resize')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2695cf57-ab2e-41b6-864e-13cb08539fac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_1 = '/home/mhkim/SuperResolution/dataset/DOTAv20/test/images/'\n",
    "path_2 = '/home/mhkim/SuperResolution/dataset/DOTAv20/test/images_x2_resize/'\n",
    "\n",
    "list_path = []\n",
    "list_path_2=[]\n",
    "\n",
    "import os\n",
    "cnt=0\n",
    "for (a,b,c) in os.walk(path_1):\n",
    "    for _c in c:\n",
    "        if 'png' in _c:\n",
    "            list_path.append(os.path.join(a,_c))\n",
    "            \n",
    "import os\n",
    "cnt=0\n",
    "for (a,b,c) in os.walk(path_2):\n",
    "    for _c in c:\n",
    "        if 'png' in _c:\n",
    "            list_path_2.append(os.path.join(a,_c))            \n",
    "\n",
    "len(list_path) == len(list_path_2)\n",
    "\n",
    "# len(list_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d6646c8-4240-4bc0-96aa-f786e4391772",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_csv = pd.read_csv('./camera_dataset/train.csv')\n",
    "test_csv = pd.read_csv('./camera_dataset/test.csv')\n",
    "train_all_input_files = './camera_dataset/train_input_img/'+train_csv['input_img']\n",
    "train_all_label_files = './camera_dataset/train_label_img/'+train_csv['label_img']\n",
    "train_input_files = train_all_input_files[120:].to_numpy()\n",
    "train_label_files = train_all_label_files[120:].to_numpy()\n",
    "\n",
    "val_input_files = train_all_input_files[:120].to_numpy()\n",
    "val_label_files = train_all_label_files[:120].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601aa9b7-141c-4738-814e-cded904268a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_root = '/home/mhkim/SuperResolution/camera_dataset'\n",
    "cut_img(train_input_files, f'{name_root}/train_input_img_')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b165697-5489-4ec7-8ec5-027ee744f52e",
   "metadata": {},
   "source": [
    "#### NUMPY TO PNG AND SAVE (func : os.makedirs / glob.glob / np.load / Image.fromarray(PIL to NUMPY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e6d7bc17-e847-4328-bc07-79244a181ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34153/34153 [12:02<00:00, 47.24it/s]\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "name_root = '/home/mhkim/SuperResolution/camera_dataset'\n",
    "name_folder = '/home/mhkim/SuperResolution/camera_dataset/train_label_img_512'\n",
    "img_path_list = glob(os.path.join(name_folder,'*'))\n",
    "img_path_list_name = os.listdir(name_folder)\n",
    "\n",
    "img_path_list_name_only = [name.split('.')[0] for name in img_path_list_name]\n",
    "\n",
    "cnt = 0\n",
    "name_saved = os.path.join(name_root,'train_label_img_512_png')\n",
    "os.makedirs(name_saved,exist_ok=True)\n",
    "for path in tqdm(img_path_list):\n",
    "    path = np.load(path)\n",
    "    new_im = Image.fromarray(path)\n",
    "    name = img_path_list_name_only[cnt]\n",
    "    new_im.save(f'{name_saved}/{name}.png')\n",
    "    cnt+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bab4779-9cdf-45c4-8368-21546f70328f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gogogog",
   "language": "python",
   "name": "mhmh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
