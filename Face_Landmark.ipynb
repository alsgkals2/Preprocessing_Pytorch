{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "03d1d414-1bed-46fc-8f74-74ebd4ee3d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "import dlib\n",
    "import cv2\n",
    "from imutils import face_utils\n",
    "import argparse\n",
    "from utils import *\n",
    "import os\n",
    "import glob\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e296f8f9-c3a2-461a-98eb-c527e262655f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3fc17dea-af27-4d9c-b29c-e4d3ad3be77d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16119"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WALK = os.walk('/media/data1/hsm/FakeAVCeleb_PREPROCESSED/FRAMES_PNG/D/TEST/')\n",
    "list_path_fake = []\n",
    "for (a,b,c) in WALK:\n",
    "    for _c in c:\n",
    "        if '.png' in _c:\n",
    "            list_path_fake.append(os.path.join(a,_c))\n",
    "list_path_fake.sort()\n",
    "\n",
    "\n",
    "len(list_path_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e34b1353-8da8-4e7a-b90a-a142b0310d00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save(path, image, jpg_quality=None, png_compression=None):\n",
    "    if jpg_quality:\n",
    "        cv2.imwrite(path, image, [int(cv2.IMWRITE_JPEG_QUALITY), jpg_quality])\n",
    "    elif png_compression:\n",
    "        cv2.imwrite(path, image, [int(cv2.IMWRITE_PNG_COMPRESSION), png_compression])  \n",
    "    else:\n",
    "        cv2.imwrite(path, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "db91254f-d381-47be-85fc-f65de19bccbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), 90]\n",
    "result, encimg = cv2.imencode('.jpg', img, encode_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "af9721e3-6111-4a8a-8977-d32743feb254",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(len(list_path_fake)):\n",
    "    imgpath = list_path_fake[i]\n",
    "    img = cv2.imread(imgpath)\n",
    "    #display the image)\n",
    "    # cv2.imshow(list_path_fake[0].replace(), img)\n",
    "    # save the image in JPEG format with 85% quality\n",
    "    outpath_jpeg = list_path_fake[i].replace('CLRNet','CLRNet_jpg25')\n",
    "    os.makedirs(os.path.dirname(outpath_jpeg),exist_ok=True)\n",
    "    save(outpath_jpeg,img,jpg_quality=25)\n",
    "#     print(outpath_jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d7a61b-7386-4ddd-a840-4afcd348ba8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9c9536-ab15-4aa3-bab1-ff2873000286",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49d5ca1e-c6eb-4a14-8a4d-309a0b44d61c",
   "metadata": {},
   "source": [
    "## COLLECTING THE PATHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "acc07b25-7053-4e9b-ad84-ed5baed3a1a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61638"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WALK = os.walk('/media/data1/mhkim/FakeAVCeleb_v1.2/MULTIMODEL_DATA/FRAMES/B_m/TRAIN/REAL/')\n",
    "\n",
    "list_path_fake = []\n",
    "for (a,b,c) in WALK:\n",
    "    for _c in c:\n",
    "        if '.png' in _c:\n",
    "            list_path_fake.append(os.path.join(a,_c))\n",
    "list_path_fake.sort()\n",
    "\n",
    "len(list_path_fake)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0bc464-d826-4f32-b431-9af6367aeb5a",
   "metadata": {},
   "source": [
    "## Start Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35cf7a40-e835-40ed-b20a-e6bbae89530c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def midpoint(p1, p2):\n",
    "    coords = (p1[0] + p2[0]) / 2, (p1[1] + p2[1]) / 2\n",
    "    return [int(x) for x in coords]\n",
    "\n",
    "def preprocessing(list_path_fake, find_main_point = False):\n",
    "    dict_landmark = {}\n",
    "    img_list = list_path_fake\n",
    "\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "    for file in img_list:\n",
    "        img = cv2.imread(file) #img must be cropped into face\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        rects = detector(gray, 0)\n",
    "\n",
    "        if len(rects) > 0:\n",
    "            for rect in rects:\n",
    "                if find_main_point:\n",
    "                    x = rect.left()\n",
    "                    y = rect.top()\n",
    "                    w = rect.right()\n",
    "                    h = rect.bottom()\n",
    "                    img = img[y:h, x:w]\n",
    "\n",
    "                shape = predictor(img, rect)\n",
    "                shape_np = face_utils.shape_to_np(shape).tolist()\n",
    "                if find_main_point:\n",
    "                    left_eye = midpoint(shape_np[36], shape_np[39])\n",
    "                    right_eye = midpoint(shape_np[42], shape_np[45])\n",
    "                    features = [left_eye, right_eye, shape_np[33], shape_np[48], shape_np[54]]\n",
    "                    dict_landmark[file] = features\n",
    "                else:\n",
    "                    dict_landmark[file] = shape_np\n",
    "    return dict_landmark\n",
    "\n",
    "dict_land_ = {}\n",
    "dict_land_ = preprocessing(list_path_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db0a1e05-b1ac-4eed-9964-51cf04bdfea8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60542"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dict_land_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6498d189-3772-47ea-b611-b799e58a55d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4943eca-1205-409d-941b-70b448e5931e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8003\n"
     ]
    }
   ],
   "source": [
    "###########temp~!!!!!!!!!!!!!!\n",
    "WALK = os.walk('/media/data1/mhkim/FakeAVCeleb_v1.2/MULTIMODEL_DATA/FRAMES/B_m/TEST/REAL/')\n",
    "\n",
    "list_path = []\n",
    "for (a,b,c) in WALK:\n",
    "    for _c in c:\n",
    "        if '.png' in _c:\n",
    "            list_path.append(os.path.join(a,_c))\n",
    "list_path.sort()\n",
    "\n",
    "print(len(list_path))\n",
    "\n",
    "def midpoint(p1, p2):\n",
    "    coords = (p1[0] + p2[0]) / 2, (p1[1] + p2[1]) / 2\n",
    "    return [int(x) for x in coords]\n",
    "\n",
    "def preprocessing(list_path, find_main_point = False):\n",
    "    dict_landmark = {}\n",
    "    img_list = list_path\n",
    "\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "    for file in img_list:\n",
    "        img = cv2.imread(file) #img must be cropped into face\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        rects = detector(gray, 0)\n",
    "\n",
    "        if len(rects) > 0:\n",
    "            for rect in rects:\n",
    "                if find_main_point:\n",
    "                    x = rect.left()\n",
    "                    y = rect.top()\n",
    "                    w = rect.right()\n",
    "                    h = rect.bottom()\n",
    "                    img = img[y:h, x:w]\n",
    "\n",
    "                shape = predictor(img, rect)\n",
    "                shape_np = face_utils.shape_to_np(shape).tolist()\n",
    "                if find_main_point:\n",
    "                    left_eye = midpoint(shape_np[36], shape_np[39])\n",
    "                    right_eye = midpoint(shape_np[42], shape_np[45])\n",
    "                    features = [left_eye, right_eye, shape_np[33], shape_np[48], shape_np[54]]\n",
    "                    dict_landmark[file] = features\n",
    "                else:\n",
    "                    dict_landmark[file] = shape_np\n",
    "    return dict_landmark\n",
    "\n",
    "dict_land_2 = {}\n",
    "dict_land_2 = preprocessing(list_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91eb88af-dbc1-4ac1-ac5d-b0e9b3119a7b",
   "metadata": {},
   "source": [
    "# SAVE DICT -> JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e627b943-7068-4b66-a9b0-bff930ebc13d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "savetitle = 'land_real_train_B'\n",
    "with open(f'{savetitle}.json','w', encoding='utf-8') as make_file:\n",
    "    json.dump(dict_land_,make_file,indent='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60992e40-bf1b-4c67-933d-26f781032599",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "savetitle = 'land_real_test_B'\n",
    "with open(f'{savetitle}.json','w', encoding='utf-8') as make_file:\n",
    "    json.dump(dict_land_2,make_file,indent='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2a32ea-5f15-4468-a428-fdcedc57b2e6",
   "metadata": {},
   "source": [
    "### LOAD JSON (FOR CHECK THE DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bb4dc591-249b-4b89-9a9d-2531bb818966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59901"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open('land_fake_train.json', 'r') as f:\n",
    "    landmarks_record =  json.load(f)\n",
    "len(landmarks_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e7ee5245-31d2-47fd-a16e-467194a3cfea",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[199, 403],\n",
       " [197, 473],\n",
       " [196, 542],\n",
       " [202, 608],\n",
       " [225, 669],\n",
       " [263, 721],\n",
       " [314, 761],\n",
       " [370, 785],\n",
       " [425, 794],\n",
       " [473, 789],\n",
       " [516, 764],\n",
       " [553, 731],\n",
       " [585, 692],\n",
       " [606, 648],\n",
       " [623, 601],\n",
       " [639, 554],\n",
       " [650, 504],\n",
       " [299, 403],\n",
       " [340, 381],\n",
       " [389, 374],\n",
       " [439, 382],\n",
       " [484, 397],\n",
       " [546, 405],\n",
       " [582, 397],\n",
       " [618, 402],\n",
       " [649, 417],\n",
       " [661, 444],\n",
       " [501, 456],\n",
       " [499, 495],\n",
       " [497, 535],\n",
       " [497, 576],\n",
       " [434, 597],\n",
       " [456, 605],\n",
       " [479, 614],\n",
       " [501, 611],\n",
       " [521, 606],\n",
       " [346, 442],\n",
       " [380, 437],\n",
       " [411, 439],\n",
       " [432, 461],\n",
       " [404, 462],\n",
       " [373, 458],\n",
       " [541, 474],\n",
       " [570, 459],\n",
       " [597, 462],\n",
       " [615, 476],\n",
       " [595, 485],\n",
       " [568, 482],\n",
       " [380, 670],\n",
       " [420, 661],\n",
       " [454, 658],\n",
       " [473, 666],\n",
       " [493, 662],\n",
       " [512, 671],\n",
       " [527, 683],\n",
       " [504, 698],\n",
       " [483, 705],\n",
       " [463, 707],\n",
       " [441, 703],\n",
       " [411, 692],\n",
       " [394, 672],\n",
       " [450, 679],\n",
       " [470, 684],\n",
       " [490, 682],\n",
       " [516, 684],\n",
       " [487, 679],\n",
       " [468, 681],\n",
       " [448, 677]]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmarks_record['/media/data1/mhkim/FakeAVCeleb_PREPROCESSED/FRAMES_PNG/C/TRAIN/FAKE/00001_0_1985/00018.png']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2ecf5688-c119-4c8e-819a-dccd41014aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "temp.append(landmarks_record[list(landmarks_record)[0]])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mhmh",
   "language": "python",
   "name": "mhmh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
